{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# reference: TensorFlow tutorials\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import cv2\n",
    "from sklearn.utils import shuffle\n",
    "import math\n",
    "import random\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import time\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load image\n",
    "classes =  ['dogs', 'cats']\n",
    "train_path = '/Users/miezai/Downloads/tensorflow-image-classification-master/train_400/'\n",
    "test_path = '/Users/miezai/Downloads/tensorflow-image-classification-master/test/'\n",
    "image_size = 128\n",
    "\n",
    "def load_image(train_path, image_size, classes):\n",
    "    images = []\n",
    "    labels = []\n",
    "    ids = []\n",
    "    cls = []\n",
    "\n",
    "    for fld in classes:\n",
    "        index = classes.index(fld)\n",
    "        path = os.path.join(train_path, fld, '*g')\n",
    "        files = glob.glob(path)\n",
    "    \n",
    "        for fl in files:\n",
    "            image = cv2.imread(fl)\n",
    "            image = cv2.resize(image, (image_size, image_size), cv2.INTER_LINEAR)\n",
    "            images.append(image)\n",
    "            label = np.zeros(len(classes))\n",
    "            label[index] = 1.0\n",
    "            labels.append(label)\n",
    "            flbase = os.path.basename(fl)\n",
    "            ids.append(flbase)\n",
    "            cls.append(fld)\n",
    "\n",
    "    images = np.array(images)\n",
    "    labels = np.array(labels)\n",
    "    ids = np.array(ids)\n",
    "    cls = np.array(cls)\n",
    "    print(\"Reading train images\")\n",
    "    \n",
    "    return images, labels, ids, cls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# helpful function from TensorFlow tutorials\n",
    "class DataSet(object):\n",
    "    def __init__(self, images, labels, ids, cls):\n",
    "        \"\"\"Construct a DataSet. one_hot arg is used only if fake_data is true.\"\"\"\n",
    "\n",
    "        self._num_examples = images.shape[0]\n",
    "        images = images.astype(np.float32)\n",
    "        images = np.multiply(images, 1.0 / 255.0)\n",
    "\n",
    "        self._images = images\n",
    "        self._labels = labels\n",
    "        self._ids = ids\n",
    "        self._cls = cls\n",
    "        self._epochs_completed = 0\n",
    "        self._index_in_epoch = 0\n",
    "\n",
    "    @property\n",
    "    def images(self):\n",
    "        return self._images\n",
    "\n",
    "    @property\n",
    "    def labels(self):\n",
    "        return self._labels\n",
    "\n",
    "    @property\n",
    "    def ids(self):\n",
    "        return self._ids\n",
    "\n",
    "    @property\n",
    "    def cls(self):\n",
    "        return self._cls\n",
    "\n",
    "    @property\n",
    "    def num_examples(self):\n",
    "        return self._num_examples\n",
    "\n",
    "    @property\n",
    "    def epochs_completed(self):\n",
    "        return self._epochs_completed\n",
    "\n",
    "    def next_batch(self, batch_size):\n",
    "        \"\"\"Return the next `batch_size` examples from this data set.\"\"\"\n",
    "        start = self._index_in_epoch\n",
    "        self._index_in_epoch += batch_size\n",
    "\n",
    "        if self._index_in_epoch > self._num_examples:\n",
    "            self._epochs_completed += 1\n",
    "\n",
    "            start = 0\n",
    "            self._index_in_epoch = batch_size\n",
    "            assert batch_size <= self._num_examples\n",
    "        end = self._index_in_epoch\n",
    "\n",
    "        return self._images[start:end], self._labels[start:end], self._ids[start:end], self._cls[start:end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_image(train_path, image_size, classes, validation_size=0):\n",
    "    class DataSets(object):\n",
    "        pass  \n",
    "    data_sets = DataSets()\n",
    "\n",
    "    images, labels, ids, cls = load_image(train_path, image_size, classes)\n",
    "    images, labels, ids, cls = shuffle(images, labels, ids, cls)  # shuffle the data\n",
    "        \n",
    "    if isinstance(validation_size, float):\n",
    "        validation_size = int(validation_size * images.shape[0])\n",
    "\n",
    "    validation_images = images[:validation_size]\n",
    "    validation_labels = labels[:validation_size]\n",
    "    validation_ids = ids[:validation_size]\n",
    "    validation_cls = cls[:validation_size]\n",
    "\n",
    "    train_images = images[validation_size:]\n",
    "    train_labels = labels[validation_size:]\n",
    "    train_ids = ids[validation_size:]\n",
    "    train_cls = cls[validation_size:]\n",
    "\n",
    "    data_sets.train = DataSet(train_images, train_labels, train_ids, train_cls)\n",
    "    data_sets.valid = DataSet(validation_images, validation_labels, validation_ids, validation_cls)\n",
    "    \n",
    "    return data_sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test\n",
    "def load_test(test_path, image_size):\n",
    "    path = os.path.join(test_path, '*g')\n",
    "    files = sorted(glob.glob(path))\n",
    "    \n",
    "    X_test = []\n",
    "    X_test_id = []\n",
    "    print(\"Reading test images\")\n",
    "    \n",
    "    for fl in files:\n",
    "        flbase = os.path.basename(fl)\n",
    "        img = cv2.imread(fl)\n",
    "        img = cv2.resize(img, (image_size, image_size), cv2.INTER_LINEAR)\n",
    "        X_test.append(img)\n",
    "        X_test_id.append(flbase)\n",
    "\n",
    "    X_test = np.array(X_test, dtype=np.uint8)\n",
    "    X_test = X_test.astype('float32')\n",
    "    X_test = X_test / 255\n",
    "\n",
    "    return X_test, X_test_id\n",
    "\n",
    "def read_test_set(test_path, image_size):  \n",
    "    images, ids  = load_test(test_path, image_size)\n",
    "    return images, ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading train images\n",
      "Reading test images\n"
     ]
    }
   ],
   "source": [
    "validation_size = 0.05\n",
    "data = read_image(train_path, image_size, classes, validation_size=validation_size)\n",
    "test_images, test_ids = read_test_set(test_path, image_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of:\n",
      "- Training-set:\t\t1874\n",
      "- Validation-set:\t98\n",
      "- Test-set:\t\t150\n"
     ]
    }
   ],
   "source": [
    "print(\"Size of:\")\n",
    "print(\"- Training-set:\\t\\t{}\".format(len(data.train.labels)))\n",
    "print(\"- Validation-set:\\t{}\".format(len(data.valid.labels)))\n",
    "print(\"- Test-set:\\t\\t{}\".format(len(test_images)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#data.test.cls = np.argmax(data.test.labels, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create weights & biases\n",
    "def create_weights(shape):\n",
    "    return tf.Variable(tf.truncated_normal(shape, stddev=0.05))\n",
    " \n",
    "def create_biases(size):\n",
    "    return tf.Variable(tf.constant(0.05, shape=[size]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#helpful functions - define layer - from TensorFlow tutorial\n",
    "def create_convolutional_layer(input,\n",
    "               num_input_channels, \n",
    "               conv_filter_size,        \n",
    "               num_filters):  \n",
    "\n",
    "    weights = create_weights(shape=[conv_filter_size, conv_filter_size, num_input_channels, num_filters])\n",
    "    biases = create_biases(num_filters)\n",
    "    layer = tf.nn.conv2d(input=input,\n",
    "                     filter=weights,\n",
    "                     strides=[1, 1, 1, 1],\n",
    "                     padding='SAME')\n",
    " \n",
    "    layer += biases\n",
    "    layer = tf.nn.max_pool(value=layer,\n",
    "                            ksize=[1, 2, 2, 1],\n",
    "                            strides=[1, 2, 2, 1],\n",
    "                            padding='SAME')\n",
    "    layer = tf.nn.relu(layer)\n",
    "    return layer\n",
    "\n",
    "def create_flatten_layer(layer):\n",
    "    layer_shape = layer.get_shape()\n",
    "    num_features = layer_shape[1:4].num_elements()\n",
    "    layer = tf.reshape(layer, [-1, num_features])\n",
    " \n",
    "    return layer\n",
    "\n",
    "def create_fc_layer(input,          \n",
    "             num_inputs,    \n",
    "             num_outputs,\n",
    "             use_relu=True):\n",
    "    weights = create_weights(shape=[num_inputs, num_outputs])\n",
    "    biases = create_biases(num_outputs)\n",
    " \n",
    "    layer = tf.matmul(input, weights) + biases\n",
    "    if use_relu:\n",
    "        layer = tf.nn.relu(layer)\n",
    " \n",
    "    return layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convolutional Layer 1.\n",
    "filter_size1 = 3 \n",
    "num_filters1 = 32\n",
    "\n",
    "# Convolutional Layer 2.\n",
    "filter_size2 = 3\n",
    "num_filters2 = 32\n",
    "# Convolutional Layer 3.\n",
    "filter_size3 = 3\n",
    "num_filters3 = 64\n",
    "\n",
    "# Parameters\n",
    "fc_size = 128            \n",
    "num_channels = 3\n",
    "img_size_flat = image_size * image_size * num_channels\n",
    "img_shape = (image_size, image_size)\n",
    "num_classes = len(classes)\n",
    "batch_size = 32\n",
    "\n",
    "x = tf.placeholder(tf.float32, shape=[None, image_size,image_size,num_channels], name='x')\n",
    "x_image = tf.reshape(x, [-1, image_size, image_size, num_channels])\n",
    "y_true = tf.placeholder(tf.float32, shape=[None, num_classes], name='y_true')\n",
    "y_true_cls = tf.argmax(y_true, dimension=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create layers\n",
    "layer_conv1 = create_convolutional_layer(input=x,\n",
    "               num_input_channels=num_channels,\n",
    "               conv_filter_size=filter_size1,\n",
    "               num_filters=num_filters1)\n",
    "layer_conv2 = create_convolutional_layer(input=layer_conv1,\n",
    "               num_input_channels=num_filters1,\n",
    "               conv_filter_size=filter_size2,\n",
    "               num_filters=num_filters2)\n",
    "layer_conv3= create_convolutional_layer(input=layer_conv2,\n",
    "               num_input_channels=num_filters2,\n",
    "               conv_filter_size=filter_size3,\n",
    "               num_filters=num_filters3)\n",
    "\n",
    "layer_flat = create_flatten_layer(layer_conv3)\n",
    "layer_shape = layer_conv3.get_shape()\n",
    "num_features = layer_shape[1:4].num_elements()\n",
    "\n",
    "layer_fc1 = create_fc_layer(input=layer_flat,\n",
    "                     num_inputs=num_features,\n",
    "                     num_outputs=fc_size,\n",
    "                     use_relu=True)\n",
    "layer_fc2 = create_fc_layer(input=layer_fc1,\n",
    "                     num_inputs=fc_size,\n",
    "                     num_outputs=num_classes,\n",
    "                     use_relu=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Predicted Class & Optimization \n",
    "y_pred = tf.nn.softmax(layer_fc2)\n",
    "y_pred_cls = tf.argmax(y_pred, dimension=1)\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits=layer_fc2,\n",
    "                                                        labels=y_true)\n",
    "cost = tf.reduce_mean(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(learning_rate=1e-4).minimize(cost)\n",
    "correct_prediction = tf.equal(y_pred_cls, y_true_cls)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "session = tf.Session()\n",
    "session.run(tf.initialize_all_variables())\n",
    "\n",
    "train_batch_size = batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total_iterations = 0\n",
    "\n",
    "def print_progress(epoch, feed_dict_train, feed_dict_validate, val_loss):\n",
    "    acc = session.run(accuracy, feed_dict=feed_dict_train)\n",
    "    val_acc = session.run(accuracy, feed_dict=feed_dict_validate)\n",
    "    msg = \"Epoch {0} --- Training Accuracy: {1:>6.1%}, Validation Accuracy: {2:>6.1%}, Validation Loss: {3:.3f}\"\n",
    "    print(msg.format(epoch + 1, acc, val_acc, val_loss))\n",
    "\n",
    "def optimize(num_iterations):\n",
    "    global total_iterations\n",
    "    start_time = time.time()\n",
    "    \n",
    "    best_val_loss = float(\"inf\")\n",
    "    patience = 0\n",
    "\n",
    "    for i in range(total_iterations,\n",
    "                   total_iterations + num_iterations):\n",
    "\n",
    "        x_batch, y_true_batch, _, cls_batch = data.train.next_batch(train_batch_size)\n",
    "        x_valid_batch, y_valid_batch, _, valid_cls_batch = data.valid.next_batch(train_batch_size)\n",
    "\n",
    "        #x_batch = x_batch.reshape(train_batch_size, img_size_flat)\n",
    "        #x_valid_batch = x_valid_batch.reshape(train_batch_size, img_size_flat)\n",
    "\n",
    "        feed_dict_train = {x: x_batch,\n",
    "                           y_true: y_true_batch}\n",
    "        \n",
    "        feed_dict_validate = {x: x_valid_batch,\n",
    "                              y_true: y_valid_batch}\n",
    "\n",
    "        session.run(optimizer, feed_dict=feed_dict_train)\n",
    "        \n",
    "        if i % int(data.train.num_examples/batch_size) == 0: \n",
    "            val_loss = session.run(cost, feed_dict=feed_dict_validate)\n",
    "            epoch = int(i / int(data.train.num_examples/batch_size))\n",
    "            \n",
    "            print_progress(epoch, feed_dict_train, feed_dict_validate, val_loss)\n",
    "            \n",
    "            #if early_stopping:    \n",
    "             #   if val_loss < best_val_loss:\n",
    "              #      best_val_loss = val_loss\n",
    "               #     patience = 0\n",
    "                #else:\n",
    "                    #patience += 1\n",
    "\n",
    "                #if patience == early_stopping:\n",
    "                 #   break\n",
    "\n",
    "    total_iterations += num_iterations\n",
    "    end_time = time.time()\n",
    "    time_dif = end_time - start_time\n",
    "    print(\"Time elapsed: \" + str(timedelta(seconds=int(round(time_dif)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 --- Training Accuracy:  59.4%, Validation Accuracy:  43.8%, Validation Loss: 0.779\n",
      "Epoch 2 --- Training Accuracy:  40.6%, Validation Accuracy:  43.8%, Validation Loss: 0.700\n",
      "Epoch 3 --- Training Accuracy:  65.6%, Validation Accuracy:  65.6%, Validation Loss: 0.687\n",
      "Epoch 4 --- Training Accuracy:  68.8%, Validation Accuracy:  65.6%, Validation Loss: 0.670\n",
      "Epoch 5 --- Training Accuracy:  68.8%, Validation Accuracy:  59.4%, Validation Loss: 0.668\n",
      "Epoch 6 --- Training Accuracy:  62.5%, Validation Accuracy:  62.5%, Validation Loss: 0.664\n",
      "Epoch 7 --- Training Accuracy:  59.4%, Validation Accuracy:  68.8%, Validation Loss: 0.630\n",
      "Epoch 8 --- Training Accuracy:  50.0%, Validation Accuracy:  59.4%, Validation Loss: 0.625\n",
      "Epoch 9 --- Training Accuracy:  56.2%, Validation Accuracy:  56.2%, Validation Loss: 0.628\n",
      "Epoch 10 --- Training Accuracy:  59.4%, Validation Accuracy:  71.9%, Validation Loss: 0.589\n",
      "Epoch 11 --- Training Accuracy:  65.6%, Validation Accuracy:  75.0%, Validation Loss: 0.527\n",
      "Epoch 12 --- Training Accuracy:  71.9%, Validation Accuracy:  71.9%, Validation Loss: 0.572\n",
      "Epoch 13 --- Training Accuracy:  78.1%, Validation Accuracy:  75.0%, Validation Loss: 0.549\n",
      "Epoch 14 --- Training Accuracy:  75.0%, Validation Accuracy:  81.2%, Validation Loss: 0.463\n",
      "Epoch 15 --- Training Accuracy:  78.1%, Validation Accuracy:  71.9%, Validation Loss: 0.518\n",
      "Epoch 16 --- Training Accuracy:  75.0%, Validation Accuracy:  71.9%, Validation Loss: 0.549\n",
      "Epoch 17 --- Training Accuracy:  81.2%, Validation Accuracy:  81.2%, Validation Loss: 0.436\n"
     ]
    }
   ],
   "source": [
    "optimize(num_iterations=9999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_accuracy(show_example_errors=False,\n",
    "                        show_confusion_matrix=False):\n",
    "    num_test = len(data.valid.images)\n",
    "    cls_pred = np.zeros(shape=num_test, dtype=np.int)\n",
    "\n",
    "    i = 0\n",
    "\n",
    "    while i < num_test:\n",
    "        j = min(i + batch_size, num_test)\n",
    "\n",
    "        images = data.valid.images[i:j, :]\n",
    "        #.reshape(batch_size, img_size_flat)\n",
    "        labels = data.valid.labels[i:j, :]\n",
    "        feed_dict = {x: images,\n",
    "                     y_true: labels}\n",
    "        cls_pred[i:j] = session.run(y_pred_cls, feed_dict=feed_dict)\n",
    "        i = j\n",
    "\n",
    "    cls_true = np.array(data.valid.cls)\n",
    "    cls_pred = np.array([classes[x] for x in cls_pred]) \n",
    "\n",
    "    correct = (cls_true == cls_pred)\n",
    "    correct_sum = correct.sum()\n",
    "\n",
    "    acc = float(correct_sum) / num_test\n",
    "\n",
    "    msg = \"Accuracy on Test-Set: {0:.1%}\"\n",
    "    print(msg.format(acc, correct_sum, num_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print_accuracy(show_example_errors=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
