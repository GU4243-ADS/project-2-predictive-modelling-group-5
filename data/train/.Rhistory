library(reticulate)
# If you are using anaconda, point reticulate to the correct conda environment
# use_condaenv('your-environment')
# for some reason I need to import cv2 and tensorflow before EBImage
# or everything breaks.
cv2 <- reticulate::import('cv2')
library(EBImage)
# This imports the cv2 package.
cv2 <- reticulate::import('cv2')
img <- cv2$imread('pet1.jpg') / 255
img_leaf <- cv2$imread('leaf.png') / 255
img_r <- EBImage::Image(aperm(img, c(2, 1, 3)), colormode = 'Color')
plot(img_r)
to_ebimage <- function(img) {
EBImage::Image(aperm(img, c(2, 1, 3)), colormode = 'Color')
}
laplacian <- cv2$Laplacian(img, cv2$CV_64F)
plot(to_ebimage(laplacian))
sobel_x <- cv2$Sobel(img, cv2$CV_64F, 1L, 0L)
sobel_y <- cv2$Sobel(img, cv2$CV_64F, 0L, 1L)
plot(to_ebimage(sobel_x))
plot(to_ebimage(sobel_y))
# We create a HOG object
# The only parameter of real importance here is winSize,
# but we are required to pass in at least this many parameters
# so that OpenCV can figure out which function we want to call.
winSize <- tuple(64L,64L)
blockSize <- tuple(16L,16L)
blockStride <- tuple(8L,8L)
cellSize <- tuple(8L,8L)
nbins = 9L
hog = cv2$HOGDescriptor(winSize,blockSize,blockStride,cellSize,nbins)
img_resized <- cv2$resize(img, dsize=tuple(64L, 64L))
hog_values <- hog$compute(np_array(img_resized * 255, dtype='uint8'))
img_gray <- cv2$cvtColor(np_array(img, dtype='float32'), cv2$COLOR_BGR2GRAY)
sift <- cv2$xfeatures2d$SIFT_create()
img_gray_uint8 <- np_array(img_gray * 255, dtype='uint8')
keypoints <- sift$detect(img_gray_uint8, NULL)
img_keypoints <- cv2$drawKeypoints(img_gray_uint8,
keypoints, NULL,
flags=cv2$DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)
plot(to_ebimage(img_keypoints / 255))
keypoints_and_values <- sift$compute(img_gray_uint8, keypoints)
values <- keypoints_and_values[[2]]
dim(values)
keypoints_dense <- apply(as.matrix(expand.grid(1:8, 1:8)), 1, function (x) {
cv2$KeyPoint((x[1] - 0.5) * 16, (x[2] - 0.5) * 16, 16)
})
img_gray_resized <- cv2$cvtColor(np_array(img_resized, dtype='float32'),
cv2$COLOR_BGR2GRAY)
img_gray_resized_uint8 <- np_array(img_gray_resized * 255, dtype='uint8')
img_keypoints_dense <- cv2$drawKeypoints(
img_gray_resized_uint8, keypoints_dense, NULL,
flags=cv2$DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)
plot(to_ebimage(img_keypoints_dense / 255))
res_dense <- sift$compute(img_gray_resized_uint8, keypoints_dense)
values_dense <- res_dense[[2]]
dim(values_dense)
# In theory, we should just be able to use the line below,
# but I have some compatibility issues.
# library(tensorflow)
tf <- import('tensorflow')
# Tensorflow uses global state, this resets it if things get
# mucked up.
tf$reset_default_graph()
model_path <- 'mobilenet_v1_0.50_224/quantized_graph.pb'
data <- with(tf$gfile$FastGFile(model_path, 'rb') %as% f, {
f$read()
})
graph_def <- tf$GraphDef()
graph_def$ParseFromString(data)
graph_elems <- tf$import_graph_def(
graph_def,
name='',
return_elements=c('input:0',
'MobilenetV1/Predictions/Reshape:0'))
graph_input <- graph_elems[[1]]
graph_output <- graph_elems[[2]]
graph_input
graph_output
img_resized <- cv2$resize(img, tuple(224L, 224L))
img_nnet <- (img_resized - 0.5) * 2
sess <- tf$Session()
input_img <- np_array(img_nnet, dtype='float32')
input_img <- input_img$reshape(1L, 224L, 224L, 3L)
features <- sess$run(
graph_output,
feed_dict=dict(graph_input=input_img))
features <- as.vector(features)
plot(features)
source("http://bioconductor.org/biocLite.R")
biocLite()
biocLite("EBImage")
library("EBImage")
img <- readImage("pet1.jpg")
print(img)
display(img)
plot(img)
n_r <- n_c <- 100
M <- matrix(img[101:(100 + n_r), 51:(50 + n_r), ], n_r, n_c)
MM <- M[,rev(1:ncol(M))]
par(mfrow=c(1,2))
image(x=1:n_r, y=1:n_c, z=M, axes = FALSE, xlab="", ylab="", col = grey(seq(0, 1, length = 256)))
image(x=1:n_r, y=1:n_c, z=MM, axes = FALSE, xlab="", ylab="", col = grey(seq(0, 1, length = 256)))
par(mfrow=c(1,1))
img_zip <- Image(M, dim=c(n_r, n_c))
plot(img_zip)
str(img)
dim(img)
imageData(img)[1:3, 1:6,]
hist(img)
img_small <- resize(img, 128, 128)
display(img_small)
img_dog <- readImage("pet2.jpg")
img_dog <- resize(img_dog, 128, 128)
img_all <- EBImage::combine(img_small, img_dog)
display(img_all, all=TRUE)
img_all2 <- EBImage::combine(img_small, flip(img_small), flop(img_small))
display(img_all2, all=TRUE)
img_bright <- img + 0.2
img_dark <- img - 0.2
display(EBImage::combine(img_bright, img_dark), all=TRUE)
img_low <- img * 0.5
img_high <- img * 2
display(EBImage::combine(img_low, img_high), all=TRUE)
img_low_c <- (img - mean(img)) * 0.5 + mean(img)
img_high_c <- (img - mean(img)) * 2 + mean(img)
display(EBImage::combine(img_low_c, img_high_c), all=TRUE)
display(img[300:450, 50:200,])
img_rotate <- translate(rotate(img, 45), c(50, 0))
display(img_rotate)
display(channel(img, mode='gray'))
display(channel(img, mode='luminance'))
w <- makeBrush(size = 31, shape = 'gaussian', sigma = 5)
plot(w[(nrow(w)+1)/2, ], ylab = "w", xlab = "", cex = 0.7)
img_flo <- filter2(img, w)
display(img_flo)
f_low <- makeBrush(21, shape='disc', step=FALSE)
display(f_low, title='Disc filter')
f_low <- f_low/sum(f_low)
img_lowPass <- filter2(img, filter=f_low)
display(img_lowPass, title='Filtered image')
f_high <- matrix(1, nc=3, nr=3)
f_high[2,2] <- -8
img_highPass <- filter2(img, f_high)
display(img_highPass, title='Filtered image')
l = length(img)
n = l/10
pixels = sample(l, n)
img_noisy = img
img_noisy[pixels] = runif(n, min=0, max=0.5)
display(img_noisy)
img_median = medianFilter(img_noisy, 1)
display(img_median)
img_bengal <- readImage("pet2.jpg")
display(img_bengal)
img_bengal_bw <- channel(img_bengal, mode="gray")
img_seg1 <- thresh(img_bengal_bw, w=60, h=60, offset=0.06) # {f = matrix(1, nc=2*w+1, nr=2*h+1) ; f=f/sum(f) ; x>(filter2(x, f)+offset)}
img_seg2 <- opening(img_seg1, kern=makeBrush(11, shape='disc'))
img_seg3 <- opening(img_seg1, kern=makeBrush(5, shape='disc'))
img_seg <- EBImage::combine(img_seg1, img_seg2, img_seg3)
display(img_seg, all=TRUE)
img_leaf <- readImage("leaf.png")
img_leaf <- resize(img_leaf, 128, 128)
img_leaf <- channel(img_leaf, mode="gray")
img_leaf1 <- thresh(img_leaf, w=50, h=50, offset=0.05)
display(EBImage::combine(img_leaf,img_leaf1), all=TRUE)
oc <- ocontour(bwlabel(img_leaf1))
plot(oc[[1]], type='l')
points(oc[[1]], col=2)
print(head(oc[[1]]))
img_bengal <- readImage("pet2.jpg")
img_bengal_bw <- channel(img_bengal, mode="gray")
img_seg1 <- thresh(img_bengal_bw, w=60, h=60, offset=0.06)
img_seg2 <- dilate(img_seg1, kern=makeBrush(25, shape='gaussian'))
img_fill <- fillHull(img_seg2)
oc_bengal <- ocontour(bwlabel(img_fill))
plot(oc_bengal[[1]], type="l")
lc <- localCurvature(x=oc[[1]], h=11)
print(head(lc$curvature))
i <- lc$curvature >= 0
neg <- array(0, dim(img_leaf1))
pos <- neg
pos[lc$contour[i,]+1]  <- lc$curvature[i]
neg[lc$contour[!i,]+1] <- -lc$curvature[!i]
display(10*(rgbImage(pos, , neg)), title = "Image curvature")
?biocLite
?source
library('EBImage')
setwd('/Users/qinqingao/Documents/GitHub/image-classification/data/train')
img <- readImage('pet10.jpg')
print(img)
display(img)
plot(img)
n_r <- n_c <- 100
M <- matrix(img[101: (100 + n_r), 51:(50 + n_r), ], n_r, n_c)
MM <- M[, rev(1:ncol(M))]
par(mfrow = c(1, 2))
image(x = 1: n_r, y = 1:n_c, z = M, axes = FALSE, xlab = '', ylab = '', col = grey(seq(0, 1, length = 256)))
image(x = 1:n_r, y = 1:n_c, z = MM, axes = FALSE, xlab = '', ylab = '', col = grey(seq(0, 1, length = 256)))
par(mfrow = c(1,1))
img_zip <- Image(M, dim = c(n_r, n_c))
plot(img_zip)
str(img)
dim(img)
imageData(img)[1:3, 1:6,]
hist(img)
img_small <- resize(img, 128, 128)
display(img_small)
img_dog <- readImage('pet79.jpg')
img_dog <- resize(img_dog, 128, 128)
img_all <- EBImage::combine(img_small, img_dog)
display(img_all, all = TRUE)
img_all2 <- EBImage::combine(img_small, flip(img_small), flop(img_small))
display(img_all2, all = TRUE)
img_bright <- img + 0.2
img_dark <- img - 0.2
display(EBImage::combine(img_bright, img_dark), all = TRUE)
img_low <- img * 0.5
img_high <- img * 2
display(EBImage::combine(img_low, img_high), all = TRUE)
img_low_c <- (img - mean(img)) * 0.5 + mean(img)
img_high_c <- (img - mean(img)) * 2 + mean(img)
display(EBImage::combine(img_low_c, img_high_c), all = TRUE)
display(img[300:450, 50:200,])
img_rotate <- translate(rotate(img, 45), c(50, 0))
display(img_rotate)
?translate
display(channel(img, mode = 'gray'))
display(channel(img, mode = 'luminance'))
w <- makeBrush(size = 31, shape = 'gaussian', sigma = 5)
plot(w[(nrow(w) + 1)/2,])
plot(w[(nrow(w) + 1)/2,], ylab = 'w', xlab = '', cex = 0.7)
img_flo <- filter2(img, w)
display(img_flo)
?filter2
?makeBrush
f_low <- makeBrush(21, shape = 'disc', step = FALSE)
display(f_low, title = 'Disc filter')
f_low <- f_low/sum(f_low)
img_lowPass <- filter2(img, filter = f_low)
display(img_lowPass, title = 'Filtered image')
f_high <- matrix(1, nc = 3, nr = 3)
f_high[2, 2] <- -8
img_highPass <- filter2(img, f_high)
display(img_highPass, title = 'Filtered image')
l = length(img)
n = l/10
pixels = sample(l, n)
img_noisy = img
img_noisy[pixels] = runif(n, min = 0, max = 0.5)
display(img_noisy)
img_median = medianFilter(img_noisy, 1)
display(img_median)
img_cat <- readImage('pet1.jpg')
display(img_cat)
img_cat_bw <- channel(img_cat, mode = 'gray')
img_seg1 <- thresh(img_cat_bw, w = 60, h = 60, offset = 0.06)
img_seg2 <- opening(img_seg1, kern = makeBrush(11, shape = 'disc'))
img_seg3 <- opening(img_seg1, kern = makeBrush(5, shape = 'disc'))
img_seg <- EBImage::combine(img_seg1, img_seg2, img_seg3)
display(img_seg, all = TRUE)
img_pet10 <- readImage('pet10.png')
img_pet10 <- readImage('pet10.jpg')
img_pet10 <- resize(img_pet10, 128, 128)
img_pet10 <- channel(img_pet10, mode = 'gray')
img_pet101 <- thresh(img_pet10, w = 50, h = 50, offset = 0.05)
display(EBImage::combine(img_pet10, img_pet101), all = TRUE)
oc <- ocontour(bwlabel(img_pet101))
plot(oc[[1]], type = 'l')
points(oc[[1]], col = 2)
print(head(oc[[1]]))
img_pet2 <- readImage('pet2.jpg')
img_pet2_bw <- channel(img_pet2, mode = 'gray')
img_seg1 <- thresh(img_pet2_bw, w = 60, h = 60, offset = 0.06)
img_seg2 <- dilate(img_seg1, kern = makeBrush(25, shape = 'gaussian'))
img_fill <- fillHull(img_seg2)
oc_pet2 <- ocontour(bwlabel(img_fill))
plot(oc_pet2[[1]], type = 'l')
lc <- localCurvature(x = oc[[1]], h = 11)
print(head(lc$curvature))
i <- lc$curvature >= 0
neg <- array(0, dim(img_pet101))
pos <- neg
pos[lc$contour[i,] + 1] <- lc$curvature[i]
neg[lc$contour[!i,] + 1] <- - lc$curvature[!i]
display(10 * (rgbImage(pos, , neg)), title = 'Image curvature')
display(img_pet101)
display(img_pet10)
display(10 * (rgbImage(pos, , neg)), title = 'Image curvature')
