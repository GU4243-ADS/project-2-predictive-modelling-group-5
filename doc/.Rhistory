setwd("~/Documents/GitHub/Spring2018/Project_Starter_Codes/doc")
if(!require("EBImage")){
source("https://bioconductor.org/biocLite.R")
biocLite("EBImage")
}
if(!require("gbm")){
install.packages("gbm")
}
library("EBImage")
library("gbm")
setwd("/Users/qinqingao/Documents/GitHub/image-classification/doc")
# Replace the above with your own path or manually set it in RStudio to where this rmd file is located.
experiment_dir <- "/Users/qinqingao/Documents/GitHub/image-classification/data/" # This will be modified for different data sets.
img_train_dir  <- paste(experiment_dir, "train/", sep="")
img_test_dir   <- paste(experiment_dir, "test/", sep="")
setwd("/Users/qinqingao/Documents/GitHub/project-2-predictive-modelling-group-5/doc")
# Replace the above with your own path or manually set it in RStudio to where this rmd file is located.
experiment_dir <- "/Users/qinqingao/Documents/GitHub/project-2-predictive-modelling-group-5/data/" # This will be modified for different data sets.
img_train_dir  <- paste(experiment_dir, "train/", sep="")
img_test_dir   <- paste(experiment_dir, "test/", sep="")
run.cv            <- TRUE # run cross-validation on the training set
K                 <- 5    # number of CV folds
run.feature.train <- TRUE # process features for training set
run.test          <- TRUE # run evaluation on an independent test set
run.feature.test  <- TRUE # process features for test set
model_values <- seq(3, 11, 2)
model_labels <- paste("GBM with depth =", model_values)
label_train <- read.table(paste(experiment_dir, "train_label.txt", sep = ""), header = F)
label_train <- as.numeric(unlist(label_train) == "dog")
source("../lib/feature.R")
tm_feature_train <- NA
if(run.feature.train){
tm_feature_train <- system.time(dat_train <- feature(img_train_dir, "train", data_name = "pet", export = TRUE))
}
tm_feature_test <- NA
if(run.feature.test){
tm_feature_test <- system.time(dat_test <- feature(img_test_dir, "test", data_name = "pet", export = TRUE))
}
#save(dat_train, file = "../output/feature_train.RData")
#save(dat_test, file = "../output/feature_test.RData")
source("../lib/train.R")
source("../lib/test.R")
source("../lib/cross_validation.R")
if(run.cv){
err_cv <- array(dim = c(length(model_values), 2))
for(k in 1:length(model_values)){
cat("k=", k, "\n")
err_cv[k,] <- cv.function(dat_train, label_train, model_values[k], K)
}
save(err_cv, file = "../output/err_cv.RData")
}
if(run.cv){
load("../output/err_cv.RData")
#pdf("../fig/cv_results.pdf", width=7, height=5)
plot(model_values, err_cv[,1], xlab = "Interaction Depth", ylab = "CV Error",
main = "Cross Validation Error", type = "n", ylim = c(0, 0.25))
points(model_values, err_cv[,1], col = "blue", pch=16)
lines(model_values, err_cv[,1], col = "blue")
arrows(model_values, err_cv[,1] - err_cv[,2], model_values, err_cv[,1] + err_cv[,2],
length = 0.1, angle = 90, code = 3)
#dev.off()
}
model_best <- model_values[1]
if(run.cv){
model_best <- model_values[which.min(err_cv[, 1])]
}
par_best <- list(depth = model_best)
tm_train <- NA
tm_train <- system.time(fit_train <- train(dat_train, label_train, par_best))
save(fit_train, file = "../output/fit_train.RData")
tm_test <- NA
if(run.test){
load(file = paste0("../output/feature_", "pet", "_", "test", ".RData"))
load(file = "../output/fit_train.RData")
tm_test <- system.time(pred_test <- test(fit_train, dat_test))
save(pred_test, file = "../output/pred_test.RData")
}
cat("Time for constructing training features=", tm_feature_train[1], "s \n")
cat("Time for constructing testing features=", tm_feature_test[1], "s \n")
cat("Time for training model=", tm_train[1], "s \n")
cat("Time for making prediction=", tm_test[1], "s \n")
if(!require("EBImage")){
source("https://bioconductor.org/biocLite.R")
biocLite("EBImage")
}
if(!require("gbm")){
install.packages("gbm")
}
library("EBImage")
library("gbm")
setwd/Users/qinqingao/Documents/GitHub/project-2-predictive-modelling-group-5/doc")
# Replace the above with your own path or manually set it in RStudio to where this rmd file is located.
if(!require("EBImage")){
source("https://bioconductor.org/biocLite.R")
biocLite("EBImage")
}
if(!require("gbm")){
install.packages("gbm")
}
library("EBImage")
library("gbm")
setwd("/Users/qinqingao/Documents/GitHub/project-2-predictive-modelling-group-5/doc")
# Replace the above with your own path or manually set it in RStudio to where this rmd file is located.
experiment_dir <- "/Users/qinqingao/Documents/GitHub/project-2-predictive-modelling-group-5/data/" # This will be modified for different data sets.
img_train_dir  <- paste(experiment_dir, "train/", sep="")
img_test_dir   <- paste(experiment_dir, "test/", sep="")
run.cv            <- TRUE # run cross-validation on the training set
K                 <- 5    # number of CV folds
run.feature.train <- TRUE # process features for training set
run.test          <- TRUE # run evaluation on an independent test set
run.feature.test  <- TRUE # process features for test set
model_values <- seq(3, 11, 2)
model_labels <- paste("GBM with depth =", model_values)
label_train <- read.table(paste(experiment_dir, "train_label.txt", sep = ""), header = F)
label_train <- as.numeric(unlist(label_train) == "dog")
source("../lib/feature.R")
tm_feature_train <- NA
if(run.feature.train){
tm_feature_train <- system.time(dat_train <- feature(img_train_dir, "train", data_name = "pet", export = TRUE))
}
tm_feature_test <- NA
if(run.feature.test){
tm_feature_test <- system.time(dat_test <- feature(img_test_dir, "test", data_name = "pet", export = TRUE))
}
#save(dat_train, file = "../output/feature_train.RData")
#save(dat_test, file = "../output/feature_test.RData")
source("../lib/train.R")
source("../lib/test.R")
source("../lib/cross_validation.R")
if(run.cv){
err_cv <- array(dim = c(length(model_values), 2))
for(k in 1:length(model_values)){
cat("k=", k, "\n")
err_cv[k,] <- cv.function(dat_train, label_train, model_values[k], K)
}
save(err_cv, file = "../output/err_cv.RData")
}
if(run.cv){
load("../output/err_cv.RData")
#pdf("../fig/cv_results.pdf", width=7, height=5)
plot(model_values, err_cv[,1], xlab = "Interaction Depth", ylab = "CV Error",
main = "Cross Validation Error", type = "n", ylim = c(0, 0.25))
points(model_values, err_cv[,1], col = "blue", pch=16)
lines(model_values, err_cv[,1], col = "blue")
arrows(model_values, err_cv[,1] - err_cv[,2], model_values, err_cv[,1] + err_cv[,2],
length = 0.1, angle = 90, code = 3)
#dev.off()
}
model_best <- model_values[1]
if(run.cv){
model_best <- model_values[which.min(err_cv[, 1])]
}
par_best <- list(depth = model_best)
tm_train <- NA
tm_train <- system.time(fit_train <- train(dat_train, label_train, par_best))
save(fit_train, file = "../output/fit_train.RData")
tm_test <- NA
if(run.test){
load(file = paste0("../output/feature_", "pet", "_", "test", ".RData"))
load(file = "../output/fit_train.RData")
tm_test <- system.time(pred_test <- test(fit_train, dat_test))
save(pred_test, file = "../output/pred_test.RData")
}
cat("Time for constructing training features=", tm_feature_train[1], "s \n")
cat("Time for constructing testing features=", tm_feature_test[1], "s \n")
cat("Time for training model=", tm_train[1], "s \n")
cat("Time for making prediction=", tm_test[1], "s \n")
head(get(load('/Users/qinqingao/Documents/GitHub/project-2-predictive-modelling-group-5/output/feature_train.RData')))
dim(get(load('/Users/qinqingao/Documents/GitHub/project-2-predictive-modelling-group-5/output/feature_train.RData')))
dim(get(load('/Users/qinqingao/Documents/GitHub/project-2-predictive-modelling-group-5/output/feature_test.RData')))
dim(get(load('/Users/qinqingao/Documents/GitHub/project-2-predictive-modelling-group-5/output/feature_pet_train.RData')))
dim(get(load('/Users/qinqingao/Documents/GitHub/project-2-predictive-modelling-group-5/output/feature_pet_test.RData')))
label_train <- read.table(paste(experiment_dir, "train_label.txt", sep = ""), header = F)
label_train
?as.numeric
?unlist
a <- unlist(label_train) == 'dog'
a
b <- as.numeric(a)
b
load('/Users/qinqingao/Desktop/Columbia/Courses/Spring 2018/STA 4243_ADS/Project 2/data/train-features/pet5.jpg.sift.Rdata')
View(features)
dim(features)
View(features)
View(features)
load('/Users/qinqingao/Desktop/Columbia/Courses/Spring 2018/STA 4243_ADS/Project 2/data/train-features/pet285.jpg.sift.Rdata')
View(features)
dim(features)
dim(get(load('/Users/qinqingao/Desktop/Columbia/Courses/Spring 2018/STA 4243_ADS/Project 2/data/train-features/pet285.jpg.sift.Rdata')))
library(reticulate)
# If you are using anaconda, point reticulate to the correct conda environment
# use_condaenv('your-environment')
# for some reason I need to import cv2 and tensorflow before EBImage
# or everything breaks.
cv2 <- reticulate::import('cv2')
library(EBImage)
# This imports the cv2 package.
cv2 <- reticulate::import('cv2')
img <- cv2$imread('pet1.jpg') / 255
img_leaf <- cv2$imread('leaf.png') / 255
img_r <- EBImage::Image(aperm(img, c(2, 1, 3)), colormode = 'Color')
plot(img_r)
to_ebimage <- function(img) {
EBImage::Image(aperm(img, c(2, 1, 3)), colormode = 'Color')
}
laplacian <- cv2$Laplacian(img, cv2$CV_64F)
plot(to_ebimage(laplacian))
sobel_x <- cv2$Sobel(img, cv2$CV_64F, 1L, 0L)
sobel_y <- cv2$Sobel(img, cv2$CV_64F, 0L, 1L)
plot(to_ebimage(sobel_x))
plot(to_ebimage(sobel_y))
# We create a HOG object
# The only parameter of real importance here is winSize,
# but we are required to pass in at least this many parameters
# so that OpenCV can figure out which function we want to call.
winSize <- tuple(64L,64L)
blockSize <- tuple(16L,16L)
blockStride <- tuple(8L,8L)
cellSize <- tuple(8L,8L)
nbins = 9L
hog = cv2$HOGDescriptor(winSize,blockSize,blockStride,cellSize,nbins)
img_resized <- cv2$resize(img, dsize=tuple(64L, 64L))
hog_values <- hog$compute(np_array(img_resized * 255, dtype='uint8'))
img_gray <- cv2$cvtColor(np_array(img, dtype='float32'), cv2$COLOR_BGR2GRAY)
sift <- cv2$xfeatures2d$SIFT_create()
img_gray_uint8 <- np_array(img_gray * 255, dtype='uint8')
keypoints <- sift$detect(img_gray_uint8, NULL)
img_keypoints <- cv2$drawKeypoints(img_gray_uint8,
keypoints, NULL,
flags=cv2$DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)
plot(to_ebimage(img_keypoints / 255))
keypoints_and_values <- sift$compute(img_gray_uint8, keypoints)
values <- keypoints_and_values[[2]]
dim(values)
keypoints_dense <- apply(as.matrix(expand.grid(1:8, 1:8)), 1, function (x) {
cv2$KeyPoint((x[1] - 0.5) * 16, (x[2] - 0.5) * 16, 16)
})
img_gray_resized <- cv2$cvtColor(np_array(img_resized, dtype='float32'),
cv2$COLOR_BGR2GRAY)
img_gray_resized_uint8 <- np_array(img_gray_resized * 255, dtype='uint8')
img_keypoints_dense <- cv2$drawKeypoints(
img_gray_resized_uint8, keypoints_dense, NULL,
flags=cv2$DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)
plot(to_ebimage(img_keypoints_dense / 255))
res_dense <- sift$compute(img_gray_resized_uint8, keypoints_dense)
values_dense <- res_dense[[2]]
dim(values_dense)
# In theory, we should just be able to use the line below,
# but I have some compatibility issues.
# library(tensorflow)
tf <- import('tensorflow')
# Tensorflow uses global state, this resets it if things get
# mucked up.
tf$reset_default_graph()
model_path <- 'mobilenet_v1_0.50_224/quantized_graph.pb'
data <- with(tf$gfile$FastGFile(model_path, 'rb') %as% f, {
f$read()
})
graph_def <- tf$GraphDef()
graph_def$ParseFromString(data)
graph_elems <- tf$import_graph_def(
graph_def,
name='',
return_elements=c('input:0',
'MobilenetV1/Predictions/Reshape:0'))
graph_input <- graph_elems[[1]]
graph_output <- graph_elems[[2]]
graph_input
graph_output
img_resized <- cv2$resize(img, tuple(224L, 224L))
img_nnet <- (img_resized - 0.5) * 2
sess <- tf$Session()
input_img <- np_array(img_nnet, dtype='float32')
input_img <- input_img$reshape(1L, 224L, 224L, 3L)
features <- sess$run(
graph_output,
feed_dict=dict(graph_input=input_img))
features <- as.vector(features)
plot(features)
